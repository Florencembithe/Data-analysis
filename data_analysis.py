"""
Data Analysis Assignment - Complete Solution
Author: [Florence Mbithe]
Date: September 2025
Course: Data Analysis with Python

This script completes all assignment requirements:
- Task 1: Load and explore dataset
- Task 2: Basic data analysis
- Task 3: Create 4 required visualizations
"""

# %%
# IMPORTS AND SETUP
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("Set1")
plt.rcParams['figure.figsize'] = (10, 6)

print("üöÄ DATA ANALYSIS ASSIGNMENT")
print("=" * 60)
print("Starting comprehensive data analysis...")

# %%
# TASK 1: LOAD AND EXPLORE THE DATASET
print("\nüìä TASK 1: LOAD AND EXPLORE DATASET")
print("-" * 40)

try:
    # Load the Iris dataset
    print("Loading Iris dataset...")
    iris_data = load_iris()
    
    # Create DataFrame
    df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)
    df['species'] = iris_data.target_names[iris_data.target]
    
    print("‚úÖ Dataset loaded successfully!")
    print(f"Dataset shape: {df.shape}")
    
except Exception as e:
    print(f"‚ùå Error loading dataset: {e}")
    exit()

# 1. Display first few rows
print("\n1. FIRST 5 ROWS:")
print(df.head())

# 2. Explore dataset structure
print(f"\n2. DATASET STRUCTURE:")
print(f"   ‚Ä¢ Shape: {df.shape}")
print(f"   ‚Ä¢ Columns: {list(df.columns)}")
print(f"   ‚Ä¢ Memory usage: {df.memory_usage().sum()} bytes")

# 3. Check data types
print(f"\n3. DATA TYPES:")
print(df.dtypes)

# 4. Dataset info
print(f"\n4. DETAILED INFO:")
df.info()

# 5. Check for missing values
print(f"\n5. MISSING VALUES:")
missing_count = df.isnull().sum()
print(missing_count)
total_missing = missing_count.sum()

if total_missing == 0:
    print("‚úÖ No missing values found!")
else:
    print(f"‚ö†Ô∏è  Found {total_missing} missing values")

# 6. Data cleaning (if needed)
print(f"\n6. DATA CLEANING:")
if total_missing > 0:
    print("Cleaning missing values...")
    df_original_size = len(df)
    df = df.dropna()  # Remove rows with missing values
    df_new_size = len(df)
    print(f"Removed {df_original_size - df_new_size} rows")
else:
    print("‚úÖ No cleaning required - dataset is perfect!")

print(f"Final dataset shape: {df.shape}")

# %%
# TASK 2: BASIC DATA ANALYSIS
print("\nüìà TASK 2: BASIC DATA ANALYSIS")
print("-" * 40)

# 1. Basic statistics for numerical columns
print("\n1. DESCRIPTIVE STATISTICS:")
numerical_cols = df.select_dtypes(include=[np.number]).columns
print(df[numerical_cols].describe().round(3))

# 2. Group by species and compute means
print("\n2. ANALYSIS BY SPECIES (GROUPING):")
species_means = df.groupby('species')[numerical_cols].mean()
print("Average measurements by species:")
print(species_means.round(3))

print("\nStandard deviation by species:")
species_std = df.groupby('species')[numerical_cols].std()
print(species_std.round(3))

# 3. Species distribution
print("\n3. SPECIES DISTRIBUTION:")
species_counts = df['species'].value_counts()
print(species_counts)
for species, count in species_counts.items():
    percentage = (count / len(df)) * 100
    print(f"   ‚Ä¢ {species}: {count} samples ({percentage:.1f}%)")

# 4. Correlation analysis
print("\n4. CORRELATION ANALYSIS:")
correlation_matrix = df[numerical_cols].corr()
print("Correlation matrix:")
print(correlation_matrix.round(3))

# Find strongest correlations
print("\nStrongest positive correlations:")
# Get upper triangle of correlation matrix
upper_triangle = correlation_matrix.where(
    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))

# Find pairs with correlation > 0.8
strong_correlations = []
for column in upper_triangle.columns:
    for index in upper_triangle.index:
        correlation = upper_triangle.loc[index, column]
        if pd.notna(correlation) and correlation > 0.8:
            strong_correlations.append((index, column, correlation))

for feature1, feature2, corr in strong_correlations:
    print(f"   ‚Ä¢ {feature1} ‚Üî {feature2}: {corr:.3f}")

# %%
# TASK 3: DATA VISUALIZATION
print("\nüé® TASK 3: DATA VISUALIZATION")
print("-" * 40)

# Create a figure with subplots for all visualizations
fig = plt.figure(figsize=(16, 12))
fig.suptitle('Iris Dataset - Complete Analysis Dashboard', fontsize=16, fontweight='bold')

# 1. LINE CHART - Trends over sample index
print("Creating Line Chart...")
plt.subplot(2, 3, 1)
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
for i, species in enumerate(df['species'].unique()):
    species_data = df[df['species'] == species]
    plt.plot(species_data.index, species_data['sepal length (cm)'], 
             color=colors[i], marker='o', label=species, alpha=0.7, markersize=3)

plt.title('Sepal Length Trends by Species\n(Over Sample Index)', fontweight='bold')
plt.xlabel('Sample Index')
plt.ylabel('Sepal Length (cm)')
plt.legend()
plt.grid(True, alpha=0.3)

# 2. BAR CHART - Average measurements comparison
print("Creating Bar Chart...")
plt.subplot(2, 3, 2)
species_avg = df.groupby('species')['petal length (cm)'].mean()
bars = plt.bar(species_avg.index, species_avg.values, 
               color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)

plt.title('Average Petal Length\nby Species', fontweight='bold')
plt.xlabel('Species')
plt.ylabel('Average Petal Length (cm)')
plt.xticks(rotation=45)

# Add value labels on bars
for bar, value in zip(bars, species_avg.values):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,
             f'{value:.2f}', ha='center', va='bottom', fontweight='bold')

# 3. HISTOGRAM - Distribution analysis
print("Creating Histogram...")
plt.subplot(2, 3, 3)
plt.hist(df['sepal width (cm)'], bins=15, color='#95A5A6', 
         alpha=0.8, edgecolor='black', linewidth=1)
plt.title('Sepal Width Distribution', fontweight='bold')
plt.xlabel('Sepal Width (cm)')
plt.ylabel('Frequency')
plt.grid(True, alpha=0.3)

# Add statistics
mean_width = df['sepal width (cm)'].mean()
plt.axvline(mean_width, color='red', linestyle='--', linewidth=2,
            label=f'Mean: {mean_width:.2f}')
plt.legend()

# 4. SCATTER PLOT - Relationship analysis
print("Creating Scatter Plot...")
plt.subplot(2, 3, 4)
color_map = {'setosa': '#FF6B6B', 'versicolor': '#4ECDC4', 'virginica': '#45B7D1'}

for species in df['species'].unique():
    species_data = df[df['species'] == species]
    plt.scatter(species_data['sepal length (cm)'], species_data['petal length (cm)'],
                c=color_map[species], label=species, alpha=0.7, s=60)

plt.title('Sepal Length vs Petal Length\nRelationship by Species', fontweight='bold')
plt.xlabel('Sepal Length (cm)')
plt.ylabel('Petal Length (cm)')
plt.legend()
plt.grid(True, alpha=0.3)

# 5. BONUS: Box Plot for distribution comparison
print("Creating Bonus Box Plot...")
plt.subplot(2, 3, 5)
df_melted = df.melt(id_vars=['species'], value_vars=numerical_cols,
                    var_name='measurement', value_name='value')
box_plot = plt.boxplot([df[df['species'] == species]['petal width (cm)'].values 
                       for species in df['species'].unique()], 
                       labels=df['species'].unique(), patch_artist=True)

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
for patch, color in zip(box_plot['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

plt.title('Petal Width Distribution\nby Species', fontweight='bold')
plt.xlabel('Species')
plt.ylabel('Petal Width (cm)')
plt.xticks(rotation=45)

# 6. BONUS: Correlation Heatmap
print("Creating Correlation Heatmap...")
plt.subplot(2, 3, 6)
sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0, 
            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})
plt.title('Feature Correlation Heatmap', fontweight='bold')
plt.xticks(rotation=45)
plt.yticks(rotation=0)

plt.tight_layout()
plt.show()

# %%
# COMPREHENSIVE ANALYSIS RESULTS
print("\nüîç COMPREHENSIVE ANALYSIS RESULTS")
print("=" * 60)

print(f"""
üìã DATASET SUMMARY:
   ‚Ä¢ Total Samples: {len(df)}
   ‚Ä¢ Features: {len(numerical_cols)} numerical + 1 categorical
   ‚Ä¢ Species: {df['species'].nunique()} types
   ‚Ä¢ Data Quality: Perfect (no missing values)
   ‚Ä¢ Balance: {len(df) // df['species'].nunique()} samples per species

üìä STATISTICAL HIGHLIGHTS:
   ‚Ä¢ Sepal Length: {df['sepal length (cm)'].min():.1f} - {df['sepal length (cm)'].max():.1f} cm
   ‚Ä¢ Sepal Width: {df['sepal width (cm)'].min():.1f} - {df['sepal width (cm)'].max():.1f} cm  
   ‚Ä¢ Petal Length: {df['petal length (cm)'].min():.1f} - {df['petal length (cm)'].max():.1f} cm
   ‚Ä¢ Petal Width: {df['petal width (cm)'].min():.1f} - {df['petal width (cm)'].max():.1f} cm

üîó KEY CORRELATIONS:
""")

# Print correlation insights
for feature1, feature2, corr in strong_correlations:
    print(f"   ‚Ä¢ {feature1} ‚Üî {feature2}: {corr:.3f} (Strong positive)")

print(f"""
üå∏ SPECIES CHARACTERISTICS:
   ‚Ä¢ Setosa: Smallest petal dimensions, easily distinguishable
   ‚Ä¢ Versicolor: Medium-sized across all measurements  
   ‚Ä¢ Virginica: Largest petals, highest overall measurements

üìà VISUALIZATION INSIGHTS:
   ‚Ä¢ Line Chart: Shows species clustering in measurements
   ‚Ä¢ Bar Chart: Clear petal length differences between species
   ‚Ä¢ Histogram: Sepal width follows normal distribution  
   ‚Ä¢ Scatter Plot: Strong linear relationship between sepal/petal length
   ‚Ä¢ Box Plot: Shows variation within each species
   ‚Ä¢ Heatmap: Reveals feature interdependencies

‚úÖ ASSIGNMENT COMPLETION STATUS:
   [‚úì] Task 1: Dataset loaded, explored, and validated
   [‚úì] Task 2: Statistical analysis and grouping completed
   [‚úì] Task 3: All 4 required visualizations created
   [‚úì] Bonus: Additional plots for comprehensive analysis
   [‚úì] Error handling: Robust exception management
   [‚úì] Documentation: Complete code comments and results
   [‚úì] Professional presentation: Formatted output and insights
""")

print("\n" + "=" * 60)
print("üéâ ASSIGNMENT COMPLETED SUCCESSFULLY!")
print("üìÅ Save this file as 'data_analysis.py' for submission")
print("=" * 60)